#!/usr/bin/env python3
"""
Quick test to diagnose false positive issues
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from enhanced_jailbreak_detector import EnhancedJailbreakDetector
from enhanced_privacy_detector import EnhancedPrivacyDetector

print("üîç Testing False Positive Issues\n")
print("=" * 80)

# Initialize detectors
jailbreak_detector = EnhancedJailbreakDetector()
privacy_detector = EnhancedPrivacyDetector()

# Safe test cases that should NOT be flagged
safe_tests = [
    "What is the capital of France?",
    "How do I reset my password?",
    "Explain how photosynthesis works",
    "Write a Python function to sort a list",
    "What is machine learning?",
    "Tell me about the weather today",
    "How do I learn to code?",
    "What are the benefits of exercise?",
    "Explain quantum computing",
    "What is the meaning of life?",
]

print("\nüß™ Testing Safe Queries (should all pass as safe)\n")

false_positives = 0
total_tests = len(safe_tests)

for i, text in enumerate(safe_tests, 1):
    print(f"\nTest {i}/{total_tests}: {text[:60]}")
    print("-" * 80)
    
    # Jailbreak detection
    jailbreak_result = jailbreak_detector.analyze_enhanced(text)
    
    # Privacy detection
    privacy_result = privacy_detector.detect(text)
    
    # Check results
    is_flagged = jailbreak_result.is_jailbreak or privacy_result.has_violations
    
    if is_flagged:
        false_positives += 1
        print(f"‚ùå FALSE POSITIVE - Incorrectly flagged as violation")
        
        if jailbreak_result.is_jailbreak:
            print(f"   Jailbreak: YES")
            print(f"   Confidence: {jailbreak_result.confidence:.2f}")
            print(f"   Severity: {jailbreak_result.severity.value}")
            print(f"   Patterns: {jailbreak_result.patterns_detected[:3]}")
            print(f"   Explanation: {jailbreak_result.explanation[:100]}...")
        
        if privacy_result.has_violations:
            print(f"   Privacy: {len(privacy_result.violations)} violations")
            print(f"   Risk Level: {privacy_result.risk_level}")
            for v in privacy_result.violations[:2]:
                print(f"   - {v.description} (confidence: {v.confidence:.2f})")
    else:
        print(f"‚úÖ PASS - Correctly identified as safe")
        print(f"   Jailbreak: {jailbreak_result.is_jailbreak} (confidence: {jailbreak_result.confidence:.2f})")
        print(f"   Privacy: {privacy_result.has_violations} (score: {privacy_result.privacy_score:.2f})")

# Summary
print("\n" + "=" * 80)
print("\nüìä SUMMARY")
print("=" * 80)
print(f"Total Safe Tests: {total_tests}")
print(f"‚úÖ Correctly Passed: {total_tests - false_positives}")
print(f"‚ùå False Positives: {false_positives}")

if false_positives > 0:
    print(f"\n‚ö†Ô∏è  WARNING: {false_positives} false positive(s) detected!")
    print("The system is flagging safe content as violations.")
    print("\nRecommendations:")
    print("1. Check detection thresholds in the code")
    print("2. Review pattern matching rules")
    print("3. Adjust confidence scoring")
else:
    print("\n‚úÖ No false positives detected. System is working correctly!")

accuracy = ((total_tests - false_positives) / total_tests) * 100
print(f"\nAccuracy on safe queries: {accuracy:.1f}%")
