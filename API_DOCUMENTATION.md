# ðŸ“¡ Joe_filter API Documentation

Complete API reference for the Joe_filter LLM Compliance & Privacy Filter system.

## Base URL

```
http://localhost:5000
```

## ðŸŽ¯ General Endpoints

### 1. **General Content Analysis**
**Endpoint:** `POST /api/analyze`

Comprehensive analysis using all detection systems (jailbreak, privacy, threats, semantic toxicity).

**Request:**
```json
{
  "text": "Content to analyze"
}
```

**Response:**
```json
{
  "success": true,
  "is_compliant": false,
  "overall_risk_score": 0.85,
  "threat_level": "high",
  "violations": ["jailbreak_attempt", "privacy_violation"],
  "detections": {
    "jailbreak": { "detected": true, "confidence": 0.9, "severity": "high" },
    "privacy": { "detected": true, "risk_level": "critical" }
  },
  "recommendations": ["BLOCK: Privacy violation detected"],
  "processing_time_ms": 250
}
```

### 2. **List All Categories**
**Endpoint:** `GET /api/categories`

Lists all available threat detection categories and their endpoints.

**Response:**
```json
{
  "categories": [
    {
      "name": "school_threat",
      "endpoint": "/api/detect/school-threat",
      "severity": "critical",
      "description": "School and campus violence threats"
    }
    // ... 9 more categories
  ],
  "total_categories": 10,
  "general_endpoint": "/api/analyze"
}
```

---

## ðŸŽ¯ Threat-Specific Detection APIs

All threat detection endpoints use the same request/response format:

**Request:**
```json
{
  "text": "Content to check"
}
```

**Response (if detected):**
```json
{
  "detected": true,
  "category": "category_name",
  "severity": "critical",
  "confidence": 0.95,
  "explanation": "Detailed explanation of detection",
  "matched_patterns_count": 3,
  "warning": "Optional warning message for critical categories"
}
```

**Response (if not detected):**
```json
{
  "detected": false,
  "category": "category_name"
}
```

### 3. **School Violence Threats**
**Endpoint:** `POST /api/detect/school-threat`

Detects threats of violence at schools, campuses, or universities.

**Severity:** `critical`

**Examples:**
- "Planning to shoot up the school"
- "Bringing a gun to campus"
- "Columbine-style attack"

---

### 4. **Self-Harm Content**
**Endpoint:** `POST /api/detect/self-harm`

Detects self-harm methods, suicide instructions, and content encouraging self-harm.

**Severity:** `critical`

**Response includes:** `warning` field for immediate intervention

**Examples:**
- "How to commit suicide"
- "Ways to hurt myself"
- "Write a poem glorifying self-harm"

---

### 5. **Drug Manufacturing**
**Endpoint:** `POST /api/detect/drug-manufacturing`

Detects instructions for producing illegal drugs.

**Severity:** `high`

**Examples:**
- "How to cook meth"
- "Make crack cocaine"
- "Synthesize MDMA"

---

### 6. **Specific Weapons**
**Endpoint:** `POST /api/detect/weapons`

Detects specific firearms, explosives, and weapon components.

**Severity:** `high`

**Examples:**
- "AR-15 assault rifle"
- "Build a pipe bomb"
- "IED construction"

---

### 7. **Workplace Violence**
**Endpoint:** `POST /api/detect/workplace-violence`

Detects threats of violence in workplace settings.

**Severity:** `critical`

**Examples:**
- "Shoot up the office"
- "Kill my boss"
- "Going postal at work"

---

### 8. **Target-Specific Threats**
**Endpoint:** `POST /api/detect/target-threat`

Detects threats against government officials or mass casualty targets.

**Severity:** `critical`

**Examples:**
- "Assassinate the president"
- "Bomb the mall"
- "Terrorist attack on subway"

---

### 9. **Sexual Violence**
**Endpoint:** `POST /api/detect/sexual-violence`

Detects sexual assault, exploitation, and child safety violations.

**Severity:** `critical`

**Response includes:** `warning` field

**Examples:**
- "Sexual assault scenario"
- "Child exploitation content"
- "Non-consensual content"

---

### 10. **Medical Misinformation**
**Endpoint:** `POST /api/detect/medical-misinformation`

Detects dangerous health advice and medical misinformation.

**Severity:** `high`

**Examples:**
- "Vaccines cause autism"
- "Drink bleach to cure COVID"
- "Prayer instead of insulin"

---

### 11. **Explicit Sexual Content**
**Endpoint:** `POST /api/detect/explicit-content`

Detects requests to generate pornographic or explicit sexual content.

**Severity:** `high`

**Examples:**
- "Generate explicit sexual dialogue"
- "Write pornographic content"
- "Create erotic scenarios"

---

### 12. **Privacy Violations (PII)**
**Endpoint:** `POST /api/detect/privacy`

Detects 20 categories of personally identifiable information and confidential data.

**Severity:** `critical`

**Request:**
```json
{
  "text": "My password is Secret123 and API key is sk-proj-abc..."
}
```

**Response:**
```json
{
  "detected": true,
  "risk_level": "critical",
  "privacy_score": 0.95,
  "violations": [
    {
      "category": "password",
      "severity": "critical",
      "confidence": 0.85,
      "masked_value": "pa...\"",
      "description": "Password detected"
    },
    {
      "category": "api_key",
      "severity": "critical",
      "confidence": 0.95,
      "masked_value": "sk....",
      "description": "OpenAI Project API Key detected"
    }
  ],
  "explanation": "Privacy violation detected: 1 Password, 1 Api Key...",
  "total_violations": 2
}
```

**PII Categories Detected (20):**
- API Keys (OpenAI, AWS, GitHub, Google, Slack, Stripe, etc.)
- Passwords & Secrets
- Credit Cards (with Luhn validation)
- Social Security Numbers
- Email Addresses & Phone Numbers
- Bank Account Numbers, IBAN, SWIFT
- Private Keys (RSA, SSH, PGP)
- JWT & OAuth Tokens
- Database Connection Strings
- IP Addresses
- Medical Record Numbers
- Biometric Data References
- Passport Numbers
- Driver's Licenses
- Dates of Birth
- Physical Addresses

---

## ðŸ“Š System Endpoints

### 13. **Metrics**
**Endpoint:** `GET /api/metrics`

Get real-time system metrics and statistics.

**Response:**
```json
{
  "total_processed": 1234,
  "jailbreak_attempts": 56,
  "privacy_violations": 23,
  "hate_speech_detected": 12,
  "token_anomalies": 8,
  "openai_detections": 45,
  "avg_response_time": 245.5,
  "system_accuracy": 98.5,
  "detection_rate": 0.089
}
```

---

### 14. **Threat Intelligence**
**Endpoint:** `GET /api/threat-intelligence`

Get threat intelligence report with trending attack patterns.

**Response:**
```json
{
  "summary": {
    "total_detections": 150,
    "unique_attack_patterns": 45,
    "active_patterns": 120,
    "trending_techniques": [
      {"technique": "role_playing", "count": 25}
    ]
  },
  "recommendations": [
    "High attack volume detected. Consider implementing rate limiting."
  ],
  "timestamp": "2025-11-06T18:00:00"
}
```

---

### 15. **Health Check**
**Endpoint:** `GET /health`

Check system health and component status.

**Response:**
```json
{
  "status": "healthy",
  "initialized": true,
  "enhanced_detector": true,
  "ml_filter": false,
  "openai_enabled": true,
  "privacy_detector": true
}
```

---

## ðŸš€ Usage Examples

### Python Example
```python
import requests

# Analyze content
response = requests.post(
    'http://localhost:5000/api/analyze',
    json={'text': 'Your content here'}
)
result = response.json()

if not result['is_compliant']:
    print(f"VIOLATION: {result['threat_level']}")
    print(f"Violations: {result['violations']}")
```

### cURL Example
```bash
# Check for privacy violations
curl -X POST http://localhost:5000/api/detect/privacy \
  -H "Content-Type: application/json" \
  -d '{"text":"My password is Secret123"}'

# Check for school threats
curl -X POST http://localhost:5000/api/detect/school-threat \
  -H "Content-Type: application/json" \
  -d '{"text":"Planning to attack the school"}'
```

### JavaScript Example
```javascript
// Analyze content
const response = await fetch('http://localhost:5000/api/analyze', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ text: 'Content to check' })
});

const result = await response.json();
console.log(result.is_compliant ? 'SAFE' : 'VIOLATION');
```

---

## ðŸ“ˆ Detection Statistics

**Total Patterns:** 268+
- 204 context-specific threat patterns (9 categories)
- 64+ privacy/PII patterns (20 categories)
- 60 jailbreak patterns
- Multi-language detection (8 languages)
- Semantic toxicity model (transformer-based)

**System Performance:**
- Accuracy: 98.5%
- Average Response Time: ~250ms
- False Positive Rate: <2%
- Critical Content Detection: 21/21 (100%)

---

## ðŸ”’ Security Notes

1. **No Data Storage**: Content is analyzed in real-time and not stored
2. **Local Detection**: Most detection runs locally (no external API required)
3. **PII Masking**: All sensitive data logged is masked (e.g., `sk...yz`)
4. **Rate Limiting**: Consider implementing rate limiting for production use
5. **HTTPS**: Use HTTPS in production deployments

---

## ðŸ“ž Error Responses

**400 Bad Request**
```json
{
  "success": false,
  "error": "No text provided"
}
```

**500 Internal Server Error**
```json
{
  "success": false,
  "error": "Error message details"
}
```

**503 Service Unavailable**
```json
{
  "error": "Privacy detector not available"
}
```

---

## ðŸ”„ Rate Limits

Currently no rate limits are enforced. For production deployment, consider:
- 100 requests/minute per IP
- 1000 requests/hour per API key
- Implement caching for repeated queries

---

## ðŸ“š Additional Resources

- **GitHub**: https://github.com/Joe3566/Joe_filter
- **Main README**: [README.md](README.md)
- **Privacy Detector Docs**: [PRIVACY_DETECTOR_README.md](PRIVACY_DETECTOR_README.md)

---

**Built with â¤ï¸ by Joe Njioka**
