#!/usr/bin/env python3
"""
ðŸŽ¯ HIGH-ACCURACY COMPLIANCE FILTER
Significantly improved ML system with balanced training data and reduced false positives.
"""

import numpy as np
import pandas as pd
import pickle
import re
import json
import time
from datetime import datetime
from typing import Dict, List, Any, Tuple, Optional
from pathlib import Path
import logging
from dataclasses import dataclass

# ML libraries
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score
from sklearn.preprocessing import StandardScaler
from sklearn.calibration import CalibratedClassifierCV

@dataclass
class AccurateFilterResult:
    """Result from high-accuracy filtering"""
    is_violation: bool
    confidence: float
    violation_type: str
    severity: str
    reasoning: List[str]
    processing_time_ms: float
    model_confidence_breakdown: Dict[str, float]
    false_positive_likelihood: float

class BalancedTrainingData:
    """Generate balanced, realistic training data to reduce false positives"""
    
    def __init__(self):
        # More realistic violation examples (fewer synthetic variations)
        self.true_violations = {
            'hate_speech': [
                "I hate all immigrants they should go back where they came from",
                "All muslims are terrorists and should be banned", 
                "Jewish people control all the banks and media",
                "Black people are inferior and belong in chains",
                "Women are too stupid to vote or work",
                "Gay people are disgusting and should be eliminated",
                "Those people don't deserve to live in our country"
            ],
            'direct_threats': [
                "I'm going to kill you tomorrow",
                "I will hunt you down and hurt you badly", 
                "You deserve to die for what you've done",
                "I'm coming to your house with a gun",
                "I'll make sure you never see another day"
            ],
            'mass_violence': [
                "Planning to shoot up the school next week",
                "Going to bomb the government building",
                "Mass shooting at the mall tomorrow",
                "Terrorist attack on the subway system"
            ],
            'severe_harassment': [
                "I will make your life hell until you kill yourself",
                "Your family will pay for your mistakes", 
                "I'll ruin your reputation and career forever"
            ],
            'privacy_violations': [
                "John Smith SSN 123-45-6789 lives at 123 Main St",
                "Credit card 4532123456789012 expires 12/25 CVV 123",
                "Email john@company.com password is secret123"
            ],
            'self_harm': [
                "I want to kill myself tonight with pills",
                "Going to jump off the bridge tomorrow",
                "Suicide is my only way out of this pain"
            ]
        }
        
        # MUCH MORE comprehensive safe content examples
        self.safe_content = [
            # Normal conversations
            "Hello, how are you doing today?",
            "Thanks for your help with the project",
            "I really enjoyed the movie last night", 
            "The weather has been beautiful this week",
            "Looking forward to the weekend plans",
            "Great job on the presentation yesterday",
            "I love spending time with my family",
            "This coffee tastes amazing this morning",
            "The sunset looks incredible from here",
            "I'm excited about the new job opportunity",
            
            # Opinions and preferences (NOT hate speech)
            "I don't really like that type of music",
            "I hate broccoli, it tastes terrible to me",
            "This movie was awful, worst I've ever seen",
            "I can't stand waiting in long lines",
            "I hate when people are late to meetings", 
            "This weather is killing my mood today",
            "That song makes me want to die of embarrassment",
            "I'm dying to see the new Marvel movie",
            "This traffic is murder on my commute",
            "I could kill for a good pizza right now",
            
            # Academic and professional content
            "Research paper on hate speech detection algorithms",
            "Analysis of violent crime statistics in urban areas",
            "Study on the effectiveness of threat assessment protocols", 
            "Academic discussion of historical genocide events",
            "Legal analysis of privacy violation cases",
            "Psychological research on suicidal ideation patterns",
            "Journalistic investigation of terrorist organizations",
            "Educational content about World War II atrocities",
            "Medical research on violence and aggression",
            "Policy discussion on immigration reform",
            
            # News and reporting
            "Breaking news: terrorist attack in foreign country",
            "Police report shooting incident downtown",
            "Court case involving hate crime charges",
            "Investigation reveals privacy data breach",
            "Suicide rates increase among teenagers",
            "Government officials threatened by protesters",
            "Immigration policy sparks heated debate",
            "Hate groups monitored by law enforcement",
            
            # Creative content
            "Writing a thriller novel about a serial killer",
            "Video game involves shooting enemy soldiers",
            "Action movie with explosions and violence",
            "Crime drama featuring murder investigation",
            "Horror story with supernatural threats",
            "War documentary showing battle scenes",
            
            # Sports and competition
            "Our team killed it in the championship game",
            "The opposing pitcher was murdering our batters",
            "I'm going to destroy you in this chess match",
            "That was a killer workout at the gym today",
            "The competition is going to be brutal this year",
            
            # Food and cooking
            "This spicy food is killing my taste buds",
            "I'm dying for some authentic Italian food",
            "That dessert was to die for, absolutely delicious",
            "I could murder a burger right about now",
            "This diet is killing me, but worth it",
            
            # Technology and gaming
            "My computer is dying, need to replace it",
            "This bug in the code is killing my productivity",
            "The server crashed and killed our website",
            "I'm going to kill this boss in the video game",
            "This app update murdered my phone's battery life",
            
            # Work and business
            "The deadline is killing our team morale",
            "Competition is murdering our market share",
            "I'm dying to close this important business deal",
            "This project is going to be the death of me",
            "We need to kill this inefficient process",
            
            # Emotional expressions (hyperbolic but safe)
            "I'm so embarrassed I could just die",
            "This assignment is killing me slowly", 
            "I'm dying of laughter at this comedy show",
            "The suspense in this book is murder",
            "I hate Mondays, they're the absolute worst",
            
            # Historical and educational
            "Learning about the Holocaust in history class",
            "Documentary about civil rights movement violence",
            "Studying the causes of ethnic conflicts",
            "Research on preventing workplace harassment",
            "Analysis of hate crime legislation effectiveness"
        ]
    
    def generate_balanced_dataset(self) -> pd.DataFrame:
        """Generate a balanced dataset with realistic examples"""
        data = []
        
        # Add violation examples (label = 1)
        for category, examples in self.true_violations.items():
            for example in examples:
                data.append({
                    'content': example,
                    'label': 1,
                    'category': category,
                    'severity': 'high' if category in ['direct_threats', 'mass_violence'] else 'medium'
                })
        
        # Add MANY more safe examples (label = 0) to balance the dataset
        for example in self.safe_content:
            data.append({
                'content': example,
                'label': 0,
                'category': 'safe',
                'severity': 'none'
            })
        
        # Add slight variations for robustness (but not too many)
        augmented_data = []
        for item in data:
            augmented_data.append(item)
            
            # Only add one variation per item to avoid overfitting
            if item['label'] == 1:  # Only augment violations slightly
                # Add one case variation
                augmented_data.append({
                    **item,
                    'content': item['content'].upper()
                })
        
        df = pd.DataFrame(augmented_data)
        
        # Ensure good balance (aim for ~70% safe, 30% violations)
        safe_count = len(df[df['label'] == 0])
        violation_count = len(df[df['label'] == 1])
        
        print(f"Training data balance: {safe_count} safe, {violation_count} violations")
        print(f"Ratio: {safe_count/(safe_count + violation_count):.1%} safe content")
        
        return df

class ImprovedTextProcessor:
    """Improved text processing with better feature engineering"""
    
    def __init__(self):
        # Common English stop words
        self.stop_words = {
            'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 
            'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 
            'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 
            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 
            'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 
            'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 
            'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 
            'at', 'by', 'for', 'with', 'through', 'during', 'before', 'after', 'above', 
            'below', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 
            'further', 'then', 'once'
        }
        
        # Context indicators that suggest non-threatening usage
        self.safe_contexts = [
            'research', 'academic', 'study', 'analysis', 'paper', 'article', 'news',
            'report', 'documentary', 'book', 'movie', 'game', 'novel', 'story',
            'history', 'historical', 'educational', 'learning', 'school', 'university',
            'journalism', 'investigation', 'court', 'legal', 'law', 'policy'
        ]
    
    def simple_tokenize(self, text: str) -> List[str]:
        """Simple tokenization"""
        text = re.sub(r'[^\w\s]', ' ', text.lower())
        tokens = [token for token in text.split() 
                 if token and len(token) > 1 and token not in self.stop_words]
        return tokens
    
    def preprocess_text(self, text: str) -> str:
        """Preprocess text for ML models"""
        # Light normalization only
        text = re.sub(r'\s+', ' ', text).strip()
        tokens = self.simple_tokenize(text)
        return ' '.join(tokens)
    
    def extract_smart_features(self, text: str) -> Dict[str, float]:
        """Extract smarter features that reduce false positives"""
        features = {}
        text_lower = text.lower()
        
        # Basic statistics
        features['char_count'] = len(text)
        features['word_count'] = len(text.split())
        
        # Threat indicators (more specific)
        direct_threats = ['i will kill you', 'going to kill', 'i will hurt you', 'coming for you']
        features['direct_threat_count'] = sum(1 for phrase in direct_threats if phrase in text_lower)
        
        # Hate speech indicators (more specific combinations)
        hate_combinations = [
            'hate all', 'kill all', 'should die', 'deserve to die',
            'should be eliminated', 'don\'t belong', 'go back where'
        ]
        features['hate_combination_count'] = sum(1 for combo in hate_combinations if combo in text_lower)
        
        # Violence indicators (context-aware)
        violence_words = ['shoot', 'bomb', 'attack', 'terrorist', 'weapon', 'gun', 'explosive']
        features['violence_word_count'] = sum(1 for word in violence_words if word in text_lower)
        
        # Safe context indicators
        features['safe_context_count'] = sum(1 for context in self.safe_contexts if context in text_lower)
        
        # Personal information
        features['has_ssn'] = 1 if re.search(r'\b\d{3}[-\s]?\d{2}[-\s]?\d{4}\b', text) else 0
        features['has_credit_card'] = 1 if re.search(r'\b\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}\b', text) else 0
        features['has_email'] = 1 if re.search(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', text) else 0
        
        # Hyperbolic expressions (often safe)
        hyperbolic_safe = ['dying to', 'to die for', 'could kill for', 'murder my', 'killing me']
        features['hyperbolic_safe_count'] = sum(1 for phrase in hyperbolic_safe if phrase in text_lower)
        
        # First person indicators (often more serious if targeting others)
        features['first_person_threat'] = 1 if re.search(r'\bi\s+(will|am going to|plan to)\s+(kill|hurt|attack)', text_lower) else 0
        
        return features

class HighAccuracyMLFilter:
    """High-accuracy ML filter with reduced false positives"""
    
    def __init__(self, model_path: str = "accurate_ml_models"):
        self.model_path = Path(model_path)
        self.model_path.mkdir(exist_ok=True)
        
        self.text_processor = ImprovedTextProcessor()
        
        # Better TF-IDF configuration to reduce overfitting
        self.vectorizer = TfidfVectorizer(
            max_features=3000,  # Reduced from 5000
            ngram_range=(1, 2),  # Reduced from (1,3)
            min_df=3,  # Increased minimum document frequency
            max_df=0.7,  # Reduced maximum document frequency
            stop_words='english'
        )
        self.scaler = StandardScaler()
        
        # Better model selection with calibration
        self.models = {
            'logistic_regression': CalibratedClassifierCV(
                LogisticRegression(C=0.1, random_state=42, class_weight='balanced'),
                cv=3
            ),
            'gradient_boosting': GradientBoostingClassifier(
                n_estimators=50,
                max_depth=3,
                learning_rate=0.1,
                random_state=42
            ),
            'calibrated_svm': CalibratedClassifierCV(
                SVC(C=0.1, kernel='rbf', random_state=42, class_weight='balanced'),
                cv=3
            )
        }
        
        self.ensemble_model = None
        self.is_trained = False
        self.training_metrics = {}
        
    def train(self, force_retrain: bool = False) -> Dict[str, Any]:
        """Train high-accuracy models with cross-validation"""
        model_file = self.model_path / "accurate_models.pkl"
        
        if model_file.exists() and not force_retrain:
            print("Loading existing accurate models...")
            return self.load_models()
        
        print("Generating balanced training dataset...")
        dataset_generator = BalancedTrainingData()
        df = dataset_generator.generate_balanced_dataset()
        
        print(f"Training on {len(df)} balanced samples...")
        
        # Preprocess text
        df['processed_content'] = df['content'].apply(self.text_processor.preprocess_text)
        
        # Create features
        X_text = self.vectorizer.fit_transform(df['processed_content'])
        
        # Extract engineered features
        feature_dicts = df['content'].apply(self.text_processor.extract_smart_features).tolist()
        X_features = pd.DataFrame(feature_dicts).fillna(0)
        X_features_scaled = self.scaler.fit_transform(X_features)
        
        # Combine features
        X_combined = np.hstack([X_text.toarray(), X_features_scaled])
        y = df['label'].values
        
        # Stratified split to maintain class balance
        X_train, X_test, y_train, y_test = train_test_split(
            X_combined, y, test_size=0.2, random_state=42, stratify=y
        )
        
        print(f"Training set: {len(X_train)} samples")
        print(f"Test set: {len(X_test)} samples")
        print(f"Test set violation ratio: {y_test.mean():.1%}")
        
        # Train models with cross-validation
        model_scores = {}
        
        for name, model in self.models.items():
            print(f"Training {name} with cross-validation...")
            
            # Cross-validation on training set
            cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1')
            
            # Train on full training set
            model.fit(X_train, y_train)
            
            # Evaluate on test set
            y_pred = model.predict(X_test)
            y_pred_proba = model.predict_proba(X_test)[:, 1]
            
            accuracy = accuracy_score(y_test, y_pred)
            f1 = f1_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred)
            recall = recall_score(y_test, y_pred)
            
            model_scores[name] = {
                'cv_f1_mean': cv_scores.mean(),
                'cv_f1_std': cv_scores.std(),
                'test_accuracy': accuracy,
                'test_f1': f1,
                'test_precision': precision,
                'test_recall': recall
            }
            
            print(f"{name} - CV F1: {cv_scores.mean():.3f} Â± {cv_scores.std():.3f}")
            print(f"         Test - Acc: {accuracy:.3f}, F1: {f1:.3f}, Prec: {precision:.3f}, Rec: {recall:.3f}")
        
        # Use best single model instead of ensemble to reduce complexity
        best_model_name = max(model_scores.keys(), key=lambda k: model_scores[k]['test_f1'])
        self.best_model = self.models[best_model_name]
        
        print(f"\nBest model: {best_model_name}")
        
        self.training_metrics = {
            'total_samples': len(df),
            'test_samples': len(X_test), 
            'best_model': best_model_name,
            'model_scores': model_scores,
            'best_test_accuracy': model_scores[best_model_name]['test_accuracy'],
            'best_test_f1': model_scores[best_model_name]['test_f1'],
            'best_test_precision': model_scores[best_model_name]['test_precision'],
            'best_test_recall': model_scores[best_model_name]['test_recall'],
            'training_date': datetime.now().isoformat()
        }
        
        self.save_models()
        self.is_trained = True
        
        return self.training_metrics
    
    def save_models(self):
        """Save trained models"""
        model_data = {
            'vectorizer': self.vectorizer,
            'scaler': self.scaler,
            'best_model': self.best_model,
            'models': self.models,
            'training_metrics': self.training_metrics,
            'text_processor': self.text_processor
        }
        
        with open(self.model_path / "accurate_models.pkl", 'wb') as f:
            pickle.dump(model_data, f)
        
        print(f"Accurate models saved to {self.model_path / 'accurate_models.pkl'}")
    
    def load_models(self) -> Dict[str, Any]:
        """Load trained models"""
        try:
            with open(self.model_path / "accurate_models.pkl", 'rb') as f:
                model_data = pickle.load(f)
            
            self.vectorizer = model_data['vectorizer']
            self.scaler = model_data['scaler'] 
            self.best_model = model_data['best_model']
            self.models = model_data['models']
            self.training_metrics = model_data['training_metrics']
            self.text_processor = model_data.get('text_processor', ImprovedTextProcessor())
            self.is_trained = True
            
            print("Accurate models loaded successfully")
            print(f"Best model: {self.training_metrics.get('best_model', 'unknown')}")
            print(f"Test accuracy: {self.training_metrics.get('best_test_accuracy', 0):.3f}")
            print(f"Test precision: {self.training_metrics.get('best_test_precision', 0):.3f}")
            
            return self.training_metrics
        
        except Exception as e:
            print(f"Error loading accurate models: {e}")
            return {}
    
    def predict(self, text: str) -> AccurateFilterResult:
        """Predict with high accuracy and low false positives"""
        if not self.is_trained:
            raise ValueError("Models not trained. Call train() first.")
        
        start_time = time.time()
        
        # Preprocess
        processed_text = self.text_processor.preprocess_text(text)
        
        # Extract features
        X_text = self.vectorizer.transform([processed_text])
        feature_dict = self.text_processor.extract_smart_features(text)
        X_features = self.scaler.transform(pd.DataFrame([feature_dict]).fillna(0))
        
        # Combine features
        X_combined = np.hstack([X_text.toarray(), X_features])
        
        # Get prediction from best model
        prediction = self.best_model.predict(X_combined)[0]
        prediction_proba = self.best_model.predict_proba(X_combined)[0]
        confidence = float(prediction_proba[1])
        
        # Get predictions from all models for confidence breakdown
        model_confidences = {}
        for name, model in self.models.items():
            try:
                model_proba = model.predict_proba(X_combined)[0]
                model_confidences[name] = float(model_proba[1])
            except:
                model_confidences[name] = 0.0
        
        # Calculate false positive likelihood based on features
        false_positive_likelihood = 0.0
        if prediction == 1:  # Only relevant for positive predictions
            # Higher likelihood if safe context indicators present
            if feature_dict.get('safe_context_count', 0) > 0:
                false_positive_likelihood += 0.3
            # Higher likelihood if hyperbolic safe expressions
            if feature_dict.get('hyperbolic_safe_count', 0) > 0:
                false_positive_likelihood += 0.2
            # Lower confidence should increase false positive likelihood
            if confidence < 0.7:
                false_positive_likelihood += 0.3
            
            false_positive_likelihood = min(false_positive_likelihood, 1.0)
        
        # Determine violation type and severity
        violation_type = "safe"
        severity = "none"
        reasoning = []
        
        if prediction == 1 and confidence > 0.5:
            text_lower = text.lower()
            
            # More specific violation type detection
            if feature_dict.get('direct_threat_count', 0) > 0:
                violation_type = "direct_threat"
                severity = "high"
                reasoning.append("Contains direct threatening language")
            elif feature_dict.get('hate_combination_count', 0) > 0:
                violation_type = "hate_speech"
                severity = "high"
                reasoning.append("Contains hate speech targeting groups")
            elif feature_dict.get('violence_word_count', 0) > 0 and feature_dict.get('safe_context_count', 0) == 0:
                violation_type = "violence"
                severity = "medium"
                reasoning.append("Contains violence-related content outside safe context")
            elif feature_dict.get('has_ssn', 0) or feature_dict.get('has_credit_card', 0):
                violation_type = "privacy_violation"
                severity = "medium"
                reasoning.append("Contains personal identifying information")
            else:
                violation_type = "general_violation"
                severity = "low"
                reasoning.append("Potential policy violation detected")
            
            # Add false positive warning if likelihood is high
            if false_positive_likelihood > 0.4:
                reasoning.append(f"WARNING: {false_positive_likelihood:.1%} chance of false positive")
        
        processing_time = (time.time() - start_time) * 1000
        
        return AccurateFilterResult(
            is_violation=bool(prediction == 1),
            confidence=confidence,
            violation_type=violation_type,
            severity=severity,
            reasoning=reasoning,
            processing_time_ms=processing_time,
            model_confidence_breakdown=model_confidences,
            false_positive_likelihood=false_positive_likelihood
        )

def main():
    """Test the high-accuracy filter"""
    print("ðŸŽ¯ HIGH-ACCURACY COMPLIANCE FILTER")
    print("=" * 50)
    
    # Initialize and train
    filter_system = HighAccuracyMLFilter()
    
    print("\nðŸ”§ Training high-accuracy models...")
    training_results = filter_system.train(force_retrain=True)
    
    print(f"\nâœ… Training Complete!")
    print(f"Best model: {training_results['best_model']}")
    print(f"Test accuracy: {training_results['best_test_accuracy']:.3f}")
    print(f"Test precision: {training_results['best_test_precision']:.3f} (low false positives)")
    print(f"Test recall: {training_results['best_test_recall']:.3f} (catches real violations)")
    print(f"Test F1: {training_results['best_test_f1']:.3f}")
    
    # Test cases focusing on false positive reduction
    test_cases = [
        # Should be SAFE (common false positives)
        "I hate broccoli with all my heart",
        "This movie was so bad it killed my brain cells",
        "I'm dying to see the new Marvel movie",
        "This traffic is murder on my commute",
        "I could kill for a good pizza right now",
        "Academic research on hate speech detection algorithms",
        "News report: terrorist attack in foreign country",
        "Historical analysis of genocide events",
        "Writing a crime novel about serial killers",
        
        # Should be VIOLATIONS (real threats)
        "I hate all immigrants and they should be eliminated",
        "I'm going to kill you tomorrow at school",
        "All muslims are terrorists and should be banned",
        "Planning to bomb the government building next week",
        "My SSN is 123-45-6789 and credit card 4532123456789012"
    ]
    
    print(f"\nðŸ§ª Testing accuracy on {len(test_cases)} cases:")
    print("-" * 80)
    
    for i, text in enumerate(test_cases, 1):
        result = filter_system.predict(text)
        
        status = "ðŸš« VIOLATION" if result.is_violation else "âœ… SAFE"
        confidence_level = "HIGH" if result.confidence > 0.8 else "MED" if result.confidence > 0.5 else "LOW"
        fp_warning = f" (FP Risk: {result.false_positive_likelihood:.1%})" if result.false_positive_likelihood > 0.3 else ""
        
        print(f"\n{i:2d}. {status} [{confidence_level}]{fp_warning}")
        print(f"    Text: '{text}'")
        print(f"    Confidence: {result.confidence:.3f} | Type: {result.violation_type}")
        
        if result.reasoning:
            print(f"    Reasoning: {'; '.join(result.reasoning)}")
    
    print(f"\nðŸŽ¯ High-accuracy filter trained and tested!")
    print(f"   Focus on reducing false positives while maintaining security")
    
    return filter_system

if __name__ == "__main__":
    main()